#+TITLE: Optimizing RaptorJIT programs
#+AUTHOR: Luke Gorrie
#+EMAIL: luke@snabb.solutions
#+LANGUAGE: en
#+OPTIONS: toc:nil num:3 H:4 ^:nil pri:t html-style:nil
#+HTML_HEAD_EXTRA: <link rel="stylesheet" type="text/css" href="org.css"/>

#+BEGIN_abstract
How to make Lua code competitive with C, C++, and Rust.
#+END_abstract

#+TOC: headlines 2

* Introduction

This is a book about how to make Lua code competitive with C, C++, and Rust.

** What is RaptorJIT?
** RaptorJIT, LuaJIT, Lua

* Tracing just-in-time compilation

/Tracing just-in-time compilation/ is a high-risk high-reward approach
to optimizing programs written in a dynamic language.

Source code written in a dynamic language is hard to compile because
many details have been deliberately left open. The only way to know
what a program really does is to run it. This is exactly what a
tracing JIT compiler does.

Specifically, the tracing JIT prepares to compile a piece of code by
actually running it in an interpreter first and recording all of the
details that became apparent at runtime: the type of each local
variable, the definition of each called function and method, and even
which conditional branches were taken and which were not. The result
is a highly detailed log of how that piece of code runs -- or at least
how it ran the one time that it was observed.

The tracing JIT then makes a bold gambit: it optimizes the code very
aggressively based on the prediction that the same code running in the
same context will tend to execute in the same way in the future too.

* How the JIT wants to compile your program

** Loop traces

Loop traces are the most important kind of trace. One loop trace is
compiled for each of the innermost loops in the program source code,
and these loops are compiled much more thoroughly than the rest of the
code thanks to /loop optimization/.

Loop optimization compiles code to execute a series of iterations
rather than just one. This is very powerful because it allows compiler
optimizations to span across multiple iterations of a loop instead of
optimizing each iteration separately without reference to the others.

Specifically,

- Later iterations can reuse values that were loaded or calculated in
  earlier iterations.
- Guards tested in the first iteration do not have to be retested in
  the following iterations.
- Stores to Lua objects can be cached and updated between iterations
  of the loop, and then committed at the end.

Loop optimization is also fragile because it only works when
successive iterations of the loop follow exactly the same code path
and "stay on trace." Each time an iteration strays from the path
recorded for the loop trace it will cause the loop to start over:
storing cached stores, reloading Lua objects, rechecking guards, and
so on.

*** Examples

Let us look at some example programs and think about which loop traces
they will have and how those loops will be compiled.

First, here are two functions to calculate the ~sum~ and ~product~ of
an array of numbers.

#+BEGIN_SRC lua -n -r
  -- Return the sum of all numbers in array.
  function sum(array)
    local acc = 0
    for _, x in ipairs(array)   (ref:sum-loop)
      acc = acc + x
    end
    return acc
  end

  -- Return the product of all numbers in array.
  function product(array)
    local acc = 0
    for _, x in ipairs(array)   (ref:product-loop)
      acc = acc * x
    end
    return acc
  end
#+END_SRC

There are two innermost loops in the source code: the ~for~ loop that
computes a sum on line [[(sum-loop)]] and the ~for~ loop that computes a
product on line [[(product-loop)]]. The JIT will compile each of these
innermost loops into a separate looping trace, and these traces will
be efficient because each one always does the same thing.

Then, here is a different implementation of those same functions:

#+BEGIN_SRC lua -n -r -i
-- Return the sum of all numbers in array.
function sum(array)
  fold(array, 0, function(x,y) x+y end)
end

-- Return the product of all numbers in array.
function product(array)
  fold(array, 0, function(x,y) x*y end)
end

function fold(array, acc, fn)
  for _, x = ipairs(array)     (ref:fold-loop)
    acc = fn(acc, x)
  end
  return acc
end
#+END_SRC

The most obvious difference is that this version passes around
higher-order functions and invokes a function object for each loop
iteration. This is actually only a small difference from the
compiler's perspective though. The JIT always inlines function calls,
even when dealing with higher-order functions, and so the apparent
indirection in the source code is all optimized away during
compilation.

The big difference is that now we only have one loop in the source
code, the ~for~ loop on line [[(fold-loop)]], and this loop will sometimes
do addition for ~sum~ but other times do multiplication for ~product~.
The compile can loop-optimize for one or the other of these cases, but
not for both. In practice this means that only one use of our naive
~fold()~ function will be compiled efficiently as a loop trace and all
other uses will be compiled inefficiently as side-traces exiting from
that loop trace.

** Side traces

Side traces are the second most important kind of trace. 

** Function traces

Function traces are a fallback.

** Exceptional cases
*** Loop unrolling
*** Instability unrolling

* How to measure performance
** Specific performance target
** Fixed workload benchmark
** Variable workload benchmark

* How to profile programs
** System profiling
*** Lua VM vs. libraries vs. kernel
*** CPU efficiency
** Lua VM profiling
*** The ideal program
*** Interpreter time
*** Garbage collector time
*** Line vs. Loop time

* Optimization patterns

** Profile interpretation patterns
*** Ideal profile

All time spent in JIT loops.

*** Healthy profile

Time is spent in JIT loops or else deliberate FFI/GC.

*** Disrupted compilation

Time spent in ~->interp~ and/or ~->return~ traces.

*** Mismatched branch bias

Side-traces taking more time than their parents.

*** Low loop factor

Low % of time is spent in looping machine code compared with line code.

** Specific hazard anti-patterns
*** Closure creation (FNEW NYI)

**** Context

Trying to reduce Disrupted compilation.

Time is attributed to a ~->interp~ trace that aborted due to ~NYI: FNEW~.

**** Problem

Function closure is being created in performance sensitive code. This cannot be JITed.

**** Solution

Reformulate code to avoid creating a closure in this code.

**** Related

*** C-API call
*** Too many local variables

** Code optimization patterns
*** Biased branch
*** Fully biased branch
*** Hoisted test
*** Split loop
*** Sunk pointer [*]
*** Eliminated branch

** Data optimization patterns
*** Freelist
*** FFI object
*** Reused C-type

